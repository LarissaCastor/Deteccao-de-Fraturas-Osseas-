# -*- coding: utf-8 -*-
"""PCA_fratura_Atv_AlgebraLinear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z5ttsOgCBqXpxdurf4j-zPXowaepl8RI

---

**Montagem do Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Importação das Bibliotecas**"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from glob import glob
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import shutil
import yaml
import random

"""**Dataset**"""

#importação da pasta com dataset
base_path = '/content/drive/MyDrive/Aula_Python_Ayslan/bonefractureyolo'
assert os.path.exists(base_path), f"Base path não existe: {base_path}"
print("Base path:", base_path)

"""**Verificação do Dataset**"""

#Lista dos componentes do diretório
contents = os.listdir(base_path)
print(f"Contents of {base_path}:")
for item in contents:
    print(item)

"""**Visualização**"""

#Determinando as extensões das imagens
IMG_EXTS = ('.jpg','.jpeg','.png','.bmp','.tif','.tiff','.JPG','.JPEG','.PNG','.BMP','.TIF','.TIFF')

#Parelhamento das imagens e rótulos que compartilham o mesmo nome base
def stem(p):
    return os.path.splitext(os.path.basename(p))[0]

#Função matemática para transformação de coordenadas em pixels
def yolo_to_xyxy(xc, yc, w, h, W, H):
    x1 = int((xc - w/2) * W); y1 = int((yc - h/2) * H)
    x2 = int((xc + w/2) * W); y2 = int((yc + h/2) * H)
    return x1, y1, x2, y2

#Localização das imagens e seus arquivos de rótulo
def list_split_files(split):
    def list_files(base, subfolders, exts):
        files = []
        for sub in subfolders:
            path = os.path.join(base, split, sub)
            if os.path.isdir(path):
                for ext in exts:
                    files.extend(glob(os.path.join(path, f'*{ext}')))
        return sorted(files)
    images = list_files(base_path, ['images', ''], IMG_EXTS)
    labels = list_files(base_path, ['labels', ''], ['.txt'])
    return images, labels

#Desenha as caixas de identificação das fraturas
def draw_boxes(img_path, label_path=None):
    bgr = cv2.imread(img_path)
    if bgr is None:
        raise ValueError(f"Não conseguiu ler {img_path}")
    img = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    H,W = img.shape[:2]
    if label_path and os.path.exists(label_path):
        with open(label_path,'r') as f:
            for ln in f:
                ln = ln.strip()
                if not ln: continue
                parts = ln.split()
                if len(parts) < 5:
                    continue
                cls = int(float(parts[0]))
                xc, yc, w, h = map(float, parts[1:5])
                x1,y1,x2,y2 = yolo_to_xyxy(xc,yc,w,h,W,H)
                cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)
                cv2.putText(img, f"cls {cls}", (x1, max(0,y1-5)),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2, cv2.LINE_AA)
    return img

"""Em seguida, foi definida a função para gerar uma amostra em grade (grid) de imagens com e sem anotações (caixas YOLO) para verificação visual da base de dados de treino, validação e teste."""

#Seleciona aleatoriamente imagens com e sem anotações de cada conjunto (train, valid, test) e exibe uma grade visual com as caixas YOLO desenhadas
def sample_images_grid(split='train', n_pos=4, n_neg=4):
    imgs, labs = list_split_files(split)
    lab_by = {stem(p):p for p in labs}
    pos, neg = [], []
    for ip in imgs:
        st = stem(ip)
        lp = lab_by.get(st)
        has_obj = False
        if lp and os.path.exists(lp):
            with open(lp,'r') as f:
                has_obj = any(ln.strip() for ln in f)
        (pos if has_obj else neg).append((ip, lp))
    print(f"[{split}] pos:{len(pos)} | neg:{len(neg)}")

    #amostra evitando repetição
    pos_s = random.sample(pos, min(n_pos, len(pos))) if pos else []
    neg_s = random.sample(neg, min(n_neg, len(neg))) if neg else []
    samples = pos_s + neg_s
    cols = 4
    rows = int(np.ceil(len(samples)/cols))
    plt.figure(figsize=(4*cols, 4*rows))
    for i,(ip,lp) in enumerate(samples):
        plt.subplot(rows, cols, i+1)
        plt.imshow(draw_boxes(ip, lp))
        plt.axis('off')
        title = 'POS' if (lp and any(open(lp).read().strip())) else 'NEG'
        plt.title(f"{split.upper()} - {title}")
    plt.tight_layout()
    plt.show()

for sp in ['train','valid','test']:
    sample_images_grid(sp, n_pos=4, n_neg=4)

"""**Transformações lineares**

rotação, espelhamento, escala, translação
"""

#Seleciona automaticamente uma imagem com anotações válidas (positiva) para visualização ou teste
def pick_positive(split='train'):
    imgs, labs = list_split_files(split)
    lab_by = {stem(p): p for p in labs}
    for ip in imgs:
        lp = lab_by.get(stem(ip))
        if lp and os.path.exists(lp):
            with open(lp,'r') as f:
                if any(ln.strip() for ln in f):
                    return ip, lp
    return None, None

ip, lp = pick_positive('train')
assert ip is not None, "Não encontrei imagem positiva no split 'train'."
img_rgb = cv2.cvtColor(cv2.imread(ip), cv2.COLOR_BGR2RGB)
img_rgb

#Rotação linear + escala 1.0
def rotate_image(img, angle_deg):
    H,W = img.shape[:2]
    M = cv2.getRotationMatrix2D((W/2, H/2), angle_deg, 1.0)
    return cv2.warpAffine(img, M, (W, H), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

#Matriz linear de escala
def scale_image(img, sx=1.2, sy=1.2):
    H,W = img.shape[:2]
    M = np.array([[sx, 0, 0],
                  [0, sy, 0]], dtype=np.float32)
    return cv2.warpAffine(img, M, (int(W*sx), int(H*sy)), flags=cv2.INTER_LINEAR)

#Translação (afim)
def translate_image(img, tx=20, ty=15):
    H,W = img.shape[:2]
    M = np.array([[1, 0, tx],
                  [0, 1, ty]], dtype=np.float32)
    return cv2.warpAffine(img, M, (W, H), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

#Reflexão (espelhamento)
def flip_image(img, horizontal=True):
    return cv2.flip(img, 1 if horizontal else 0)

#Visualização
variants = {
    'Original': img_rgb,
    'Rot. +15°': rotate_image(img_rgb, 15),
    'Rot. -15°': rotate_image(img_rgb, -15),
    'Flip H': flip_image(img_rgb, True),
    'Escala 1.2x': scale_image(img_rgb, 1.2, 1.2),
    'Translação (20,15)': translate_image(img_rgb, 20, 15),
}

plt.figure(figsize=(16,8))
for i,(k,im) in enumerate(variants.items(), 1):
    plt.subplot(2,3,i); plt.imshow(im); plt.axis('off'); plt.title(k)
plt.tight_layout(); plt.show()

"""**PCA nas imagens**

-> um estudo da aplicação do PCA em imagens já segmentadas/anotadas, para analisar e comprimir as imagens já pré-classificadas (fratura ou não fratura) gerando a possibilidade de estabelecer padrões de fraturas (ex.: total, parcial, deslocadas)

Decisões técnicas para PCA neste contexto:

* Converter imagens para tons de cinza, redimensionar para um tamanho fixo para reduzir dimensionalidade.

* Flatten em vetores 1D.

* Centralizar as features (média zero).

* Treinar PCA apenas no split de treino, depois transformar valid e test.

"""

#Carregamento e conversão das imagens em vetores, gerando matrizes de dados e rótulos para o PCA.
def load_split_as_matrix(split='train', size=(128,128), max_n=None):
    imgs, labs = list_split_files(split)
    lab_by = {stem(p): p for p in labs}
    X, y, paths = [], [], []
    count = 0
    for ip in imgs:
        if max_n and count >= max_n: break
        bgr = cv2.imread(ip)
        if bgr is None:
            continue
        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, size, interpolation=cv2.INTER_AREA)
        vec = gray.astype(np.float32).ravel()
        lp = lab_by.get(stem(ip))
        has_obj = False
        if lp and os.path.exists(lp):
            with open(lp,'r') as f:
                has_obj = any(ln.strip() for ln in f)
        X.append(vec); y.append(1 if has_obj else 0); paths.append(ip)
        count += 1
    X = np.vstack(X) if len(X)>0 else np.array([])
    y = np.array(y)
    return X, y, paths

#Carregamento dos dados
img_size = (128,128)
X_train, y_train, p_train = load_split_as_matrix('train', img_size)
X_valid, y_valid, p_valid = load_split_as_matrix('valid', img_size)
X_test , y_test , p_test  = load_split_as_matrix('test' , img_size)

print("Shapes ->",
      "X_train:", X_train.shape, "X_valid:", X_valid.shape, "X_test:", X_test.shape)

#Centralização (sem padronizar variância, apenas remover média)
scaler = StandardScaler(with_mean=True, with_std=False)
X_train_c = scaler.fit_transform(X_train)
X_valid_c = scaler.transform(X_valid)
X_test_c  = scaler.transform(X_test)

#Ajuste do PCA exploratório e cálculo da variância explicada acumulada.
pca_expl = PCA(n_components=None, svd_solver='full', random_state=42).fit(X_train_c)
cum_var = np.cumsum(pca_expl.explained_variance_ratio_)

"""**Curva de variância explicada**

* criação do gráfico de variância explicada acumulada e cálculo de quantos componentes principais são necessários para explicar 90% e 95% da variância dos dados.
"""

#Visualização da curva de variância explicada
plt.figure(figsize=(8,6))
plt.plot(np.arange(1, len(cum_var)+1), cum_var, marker='o', linewidth=1)
plt.xlabel('Número de componentes principais')
plt.ylabel('Variância explicada acumulada')
plt.title('PCA — Curva de variância explicada (train)')
plt.grid(True, linestyle='--', alpha=0.4)
plt.xlim(0, 200)
plt.axhline(y=0.90, color='r', linestyle='--', label='90%')
plt.axhline(y=0.95, color='g', linestyle='--', label='95%')
plt.legend()
plt.show()

"""* Esse gráfico mostra o quanto da variância total dos dados é preservada conforme aumentamos o número de componentes principais, permitindo identificar quantos componentes são suficientes para explicar 90% e 95% da variância do dataset."""

#Identificação do número de componentes principais
pca90 = PCA(n_components=0.90, svd_solver='full', random_state=42).fit(X_train_c)
pca95 = PCA(n_components=0.95, svd_solver='full', random_state=42).fit(X_train_c)

print("Componentes escolhidos p/ 90%:", pca90.n_components_)
print("Componentes escolhidos p/ 95%:", pca95.n_components_)

#Aplicação da transformação da Análise de Componentes Principais (PCA) aos seus conjuntos de dados
pca = PCA(n_components=114, svd_solver='full', random_state=42).fit(X_train_c)
Z_train = pca.transform(X_train_c)
Z_valid = pca.transform(X_valid_c)
Z_test  = pca.transform(X_test_c)

"""* Para demonstrar o caráter linear e cumulativo do PCA, cada componente adicional incorpora uma fração da variância total dos dados, melhorando a fidelidade da imagem reconstruída. Para tanto, será definida a seguir a função 'reconstruct_with_k'."""

#Reconstrução da imagem usando diferentes números de componentes principais
def reconstruct_with_k(pca, Z, scaler, idx, k_list=(5, 10, 33, 50, 114), shape=(128,128)):
    original_centered = pca.inverse_transform(Z[idx])                               #usando todos os comps ajustados
    imgs = {}
    for k in k_list:                                                                #simulação de k comps, zerando o restante e descentralizando
        zk = np.zeros_like(Z[idx])
        zk[:min(k, Z.shape[1])] = Z[idx][:min(k, Z.shape[1])]
        xk_centered = pca.inverse_transform(zk)
        xk = scaler.mean_ + xk_centered
        imgs[k] = xk.reshape(shape)

    #original
    xfull = scaler.mean_ + original_centered
    imgs['Full'] = xfull.reshape(shape)
    return imgs

#escolha do índice e reconstruição
idx = np.random.randint(0, len(Z_train))
rec = reconstruct_with_k(pca, Z_train, scaler, idx, k_list=(5,10,33,50,114), shape=img_size)

plt.figure(figsize=(14,3))
plt.subplot(1,6,1); plt.imshow(rec[5], cmap='gray'); plt.axis('off'); plt.title('k=5')
plt.subplot(1,6,2); plt.imshow(rec[10], cmap='gray'); plt.axis('off'); plt.title('k=10')
plt.subplot(1,6,3); plt.imshow(rec[33], cmap='gray'); plt.axis('off'); plt.title('k=33')
plt.subplot(1,6,4); plt.imshow(rec[50], cmap='gray'); plt.axis('off'); plt.title('k=50')
plt.subplot(1,6,5); plt.imshow(rec[114], cmap='gray'); plt.axis('off'); plt.title('k=114')
plt.subplot(1,6,6); plt.imshow(rec['Full'], cmap='gray'); plt.axis('off'); plt.title('Full')
plt.tight_layout(); plt.show()

"""* Essa foi uma análise visual da reconstrução de imagens a partir de diferentes números de componentes principais obtidos pelo PCA. O objetivo é observar como o PCA representa e comprime informações em imagens, reconstruindo-as gradualmente conforme o número de componentes (k) aumenta.

* A reconstrução com um número pequeno de componentes mostra apenas as estruturas globais, sem detalhes finos. À medida que aumentamos k, a textura, contraste e bordas são gradualmente recuperados. E, quando k se aproxima do número total de componentes, a reconstrução se torna quase idêntica à imagem original.

* Logo, o PCA permitiu reduzir a dimensionalidade preservando a maior parte da informação visual, e essa reconstrução mostra o equilíbrio entre compressão e qualidade da informação.

**Visualização 2D (PC1 vs PC2) com cores por classe**

**Reconstrução com PCA**
* demonstração de compressão
"""

#Distribuição dos dados nos dois primeiros componentes principais
def scatter_pc12(Z, y, split_name, max_pts=2000):
    idx = np.arange(len(y))
    if len(idx) > max_pts:
        np.random.seed(42); idx = np.random.choice(idx, max_pts, replace=False)
    Zs, ys = Z[idx], y[idx]
    plt.figure(figsize=(6,5))
    plt.scatter(Zs[:,0], Zs[:,1], c=ys, s=8, alpha=0.7)
    plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title(f'PCA: PC1 vs PC2 — {split_name}')
    cb = plt.colorbar(); cb.set_label('has_object (0=NEG, 1=POS)')
    plt.grid(True, linestyle='--', alpha=0.3); plt.show()

scatter_pc12(Z_train, y_train, 'Train')
scatter_pc12(Z_valid, y_valid, 'Valid')
scatter_pc12(Z_test , y_test , 'Test')

"""---

**REFERÊNCIA**

Dados obtidos no ResearchGate

Dataset: [Bone Fracture Detection: Computer Vision Project](https://www.researchgate.net/publication/382268240_Bone_Fracture_Detection_Computer_Vision_Project)

Darabi, Parisa. (2024). Bone Fracture Detection: Computer Vision Project. 10.13140/RG.2.2.14400.34569.
"""